## AWS EC2

AWS EC2에서 t2.small 로 지정(최소 메모리 1기가 이상)

- 카프카(9092), 주키퍼(2182) 포트 사용 → 인바운드 옵션에서 열어주어야함

## 로컬에서 접속

remote ssh 연동

- ssh -i {키이름절대경로} ec2-user@{Public IPV4}

`config/server.properties`

- `advertiesed.listeners=PLAINTEXT://your.host.name:9092` 에서 your.host.name을 
현재 public IPv4로 교체하여 저장
- e.g : advertiesed.listeners=PLAINTEXT://1.234.567.89:9092

주키퍼 실행 

bin/zookeeper-server-start.sh -daemon config/zookeeper.properties 

jps -vm

카프카 실행

bin/kafka-server-start.sh -daemon config/server.properties 

jps -m

tail -f logs/server.log

jps : JVM process 상태

-v : JVM에 전달된 인자

-m : main메서드에 전달된 인자

-daemon : 백그라운드에서 실행하겠다

## 2.1.5 로컬에서 서버 호스트 설정

`curl https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12_2.5.0.tgz --output kafka.tgz` 

`tar -xvf kafka.tgz`

- 서버에서 받은 kafka는 카프카브로커가있는 카프카버전
- 로컬에서 받은 건 카프카 바이너리패키지에 들어있는 카프카버전.
- 로컬에서 카프카 커맨드 라인 툴을 사용해야하기 때문

`vi /etc/hosts`

- 이거 관리자권한 필요하니까 `sudo vi /etc/hosts`
- to allow the same kube 어쩌구 하단에 **{PUBLIC IPv4}** 무조건 탭!!!!!!! {NAME}
    
    ```jsx
    ##
    # Host Database
    #
    # localhost is used to configure the loopback interface
    # when the system is booting.  Do not change this entry.
    ##
    127.0.0.1       localhost
    255.255.255.255 broadcasthost
    ::1             localhost
    # Added by Docker Desktop
    # To allow the same kube context to work on the host and the container:
    127.0.0.1 kubernetes.docker.internal
    1.234.56.789  my-kafka
    # End of section
    "/etc/hosts" [readonly] 14L, 389B
    ```
    
- 이때부터 Public IPv4 1.234.56.789는 my-kafka로 접속할수있게된다
- 이때부터는 my-kafka:카프카포트번호 로 접속함

## 2.2 카프카 CLI

연동상태 : 로컬 카프카 CLI - AWS EC2 카프카브로커

- 가능한것 : 토픽생성,수정, 데이터전송(프로듀서),받기(컨슈머)

토픽

- 카프카에서 데이터를 구분하는 가장 기본적인 개념
- 여러개의 토픽이 존재할수있고
- 토픽에는 파티션이 존재하는데 파티션의 갯수는 최소 1개임

`kafka-topics.sh`

- 토픽에 대한 기본적인 명령어

```jsx
bin/kafka-topics.sh \
--create \
--bootstrap-server my-kafka:9092 \
--topic hello.kafka
```

create : 만들겠다

bootstrap-server : {카프카 클러스터} {브로커IP 포트번호}

topic : 토픽이름

```jsx
bin/kafka-topics.sh \
--create \
--bootstrap-server my-kafka:9092 \
--partitions 3 \
--replication-factor 1 \
--config retention.ms=172800000 \
--topic hello.kafka.2
```

partitions : 파티션갯수(3개), 디폴트 : config/server.properties

replicationfactor : 토픽파티션의 복제갯수. 1은 복제안함, 2는 1개의 복제본 사용.

config : 추가설정

> 토픽생성시 -zookeeper가 아니라 -bootstrap-server를 사용하는 이유는
(구버전) 카프카 CLI - 주키퍼 : 주키퍼를통해서 다시 카프카로 통신하면 아키첵텨의 복잡도가 높아졌고
(신버전) 카프카 CLI - 부트스트랩 : 직접 카프카와 통신하여 아키텍쳐의 복잡도를 낮춘다
> 

카프카 리스트 확인

```jsx
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list hello.kafka
```

토픽상세조회

```jsx
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2

```

Leader파티션 : -번 브로커에 위치하고있는지

토픽옵션수정

`kafka-topics.sh` : 토픽의 파티션 갯수 변화

`kafka-configs.sh` : 토픽의 설정 변화

```jsx
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--alter \
--partitions 4
```

hello.kafka 토픽을 수정할건데 partitions를 4개로 수정하겠다 (늘리는건가능, 없에는건 불가능)

```jsx
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--describe
```

hello.kafka토픽을 볼건데 얘의 세부기능을 보겠다

```jsx
bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
--entity-type topics \
--entity-name hello.kafka \
--alter --add-config retention.ms=86400000
```

객체 타입은 토픽이고, 객체이름은 hello.kafka인데 얘의 리텐션기간을86400000로 바꾸겠다

리텐션기간 : 토픽이 자동으로 없어지는 기한

```jsx
bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
--entity-type topics \
--entity-name hello.kafka \
--describe 
```

객체 타입은 토픽이고, 객체이름은 hello.kafka인데, 얘의 세부사항을 보겠다

## 2.2.2 kafka-console-producer.sh

`kafka-console-producer.sh`  

- 토픽에다가 데이터를 넣는 기술
- 토픽에 넣는 데이터는 Record라고 부르며, 키-밸류 로 구성되어있다
- 전송되는 레코드 값은 UTF-8기반으로 변환되고, ByteArraySerializer로 직렬화된다

```jsx
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka
```

데이터를 넣을건데 토픽이름은 hello.kafka다 

```jsx
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--property "parse.key=true" \
--property "key.separator=:"

key1:no1
key2:no2
key3:no3

```

parse.key true : 레코드를 전송할때 메세지키를 보내겠다

keyseparator : 구분자를 선언하겠다 . 여기서는 : 가 역할을함

## 2.2.3 kafka-console-consumer.sh

`kafka-console-consumer.sh` : 방금 위에서 프로듀서로 보냇으니, 컨슈머(받은애)를 확인할거다

```jsx
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
> --topic hello.kafka \
> --from-beginning
```

topic 이름은 이거고, from-beginning : 가장처음부터 데이터를 출력한다

```jsx
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
> --topic hello.kafka \
> --property print.key=true \
> --property key.separator="-" \
> --group hello-group \
> --from-beginning
```

print.key=true 데이터를 볼거고, key.separator 키 구분은 이거고, group 그룹을 만들건데 그룹이름은 이거고, from-beginning 처음부터 보겠다

데이터와 메세지키- 메세지벨류 를 같이보게됨

## 2.2.4 kafka-consumer-groups.sh

`kafka-consumer-groups.sh` 컨슈머 그룹으로 생성된 컨슈머로 - 토픽을 가져가서 지정해주는것

```jsx
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list \
hello-group
```

그룹이름은 저거다 

```jsx
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 \
--group hello-group \
--describe 
```

그룹이름은 이거고 describe 명세해서보겠다

## 2.2.5 kafka-verifiable-producer,consumer

`kafka-verifiable-producer.sh` or `kafka-verifiable-consumer.sh`: 프로듀서와 컨슈머끼리 string타입 메세지값을 코드없이 주고받을 수 있다

```jsx
bin/kafka-verifiable-producer.sh --bootstrap-server my-kafka:9092 \
> --max-messages 10 \
> --topic verify-test
```

verify-test토픽으로 임의 토픽을 보낸다 

```jsx
bin/kafka-verifiable-consumer.sh --bootstrap-server my-kafka:9092 \
> --topic verify-test \
> --group-id test-group
```

데이터를 가져오고자 하는 토픽이름은 verify-test 이고, group-id 은 컨슈머 그룹을 지정함(test-group) 이 이름

## 2.2.6 kafka-delete-records.sh

`kafka-delete-records.sh` : 적재된 토픽의 데이터를 지우는 법

delete-toppic.json 파일을 만들어서, 이걸 kafka-delete-records.sh로 보내는 방법이 존재함

```jsx
# vi delete-topic.json
{"partitions": [{"topic": "test", "partition": 0, "offset": 50}], "version":1 }

```

```jsx
bin//kafka-delete-records.sh --bootstrap-server my-kafka:9092 \
> --offset-json-file delete-topic.json
```